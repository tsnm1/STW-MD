{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rpy2\n",
    "# from rpy2.robjects import r\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "plt.rcParams['font.family'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv('AMP-AD_MSBB_MSSM_covariates_mRNA_AffymetrixU133AB.tsv', sep='\\t')\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = info.groupby(by='CDR').count().reset_index()\n",
    "stage['stage'] = ('CDR' + stage['CDR'].astype(str))\n",
    "stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(stage['stage'], stage['BrainBank'], width=0.3, color='tan')  # , color='tan'\n",
    "for i in range(len(stage)):\n",
    "    plt.text(stage['stage'][i], stage['BrainBank'][i] + 0.1, stage['BrainBank'][i], ha='center', va='bottom')\n",
    "plt.ylim((0, 25))\n",
    "plt.ylabel('Number of Individuals')\n",
    "\n",
    "ax = plt.gca()  # Get the axis\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# ax.axis.grid(color='lightgray', linewidth=0.5, alpha=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micepath = 'D:/'\n",
    "micefiles = os.listdir('D:')\n",
    "\n",
    "AllFC = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDR10 = []\n",
    "CDR20 = []\n",
    "CDR21 = []\n",
    "\n",
    "up_gene10 = []\n",
    "down_gene10 = []\n",
    "up_gene20 = []\n",
    "down_gene20 = []\n",
    "\n",
    "CDRAll = set()\n",
    "gene_num = []\n",
    "patients = []\n",
    "\n",
    "dif_gene = pd.DataFrame()\n",
    "dif_gene['Num'] = range(1, 20)\n",
    "dif_gene['Region'] = 'Region' + dif_gene['Num'].astype(str)\n",
    "\n",
    "# Record the number of differential genes in each region (excluding duplicates in the three-stage comparison)\n",
    "dif_gene['dif_gene_num'] = np.nan\n",
    "\n",
    "# Record the number of differential genes in the three-stage comparison\n",
    "dif_gene['CDR1VSCDR0'] = np.nan\n",
    "dif_gene['CDR2VSCDR0'] = np.nan\n",
    "dif_gene['CDR2VSCDR1'] = np.nan\n",
    "\n",
    "# Record the number of upregulated genes and downregulated genes in each region (Mid-stage VS Early stage 10, Late-stage VS Early stage 20)\n",
    "dif_gene['up_gene10'] = np.nan\n",
    "dif_gene['down_gene10'] = np.nan\n",
    "dif_gene['up_gene20'] = np.nan\n",
    "dif_gene['down_gene20'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDRframe = pd.read_csv(micepath+micefiles[0])\n",
    "CDRframe.dropna(inplace=True)\n",
    "conmon_gene = CDRframe['genename'].to_list()\n",
    "len(conmon_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(micefiles)):\n",
    "    data = pd.read_csv(micepath+micefiles[i])\n",
    "    data.dropna(inplace=True)\n",
    "    genename = data['genename'].to_list()\n",
    "\n",
    "    conmon_gene = [i for i in conmon_gene if i in genename]\n",
    "len(conmon_gene)\n",
    "# pd.DataFrame(conmon_gene,columns=['genename']).to_csv('conmon_gene_18431.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDR10 = []\n",
    "CDR20 = []\n",
    "CDR21 = []\n",
    "\n",
    "up_gene10 = []\n",
    "down_gene10 = []\n",
    "up_gene20 = []\n",
    "down_gene20 = []\n",
    "\n",
    "CDRAll = set()\n",
    "gene_num = []\n",
    "patients = []\n",
    "\n",
    "dif_gene = pd.DataFrame()\n",
    "dif_gene['Num'] = range(1, len(micefiles) + 1)\n",
    "dif_gene['Region'] = 'Region' + dif_gene['Num'].astype(str)\n",
    "\n",
    "# Record the number of times each patient appears\n",
    "for i in range(len(micefiles)):\n",
    "    data = pd.read_csv(micepath + micefiles[i])\n",
    "    data = data[data['genename'].isin(conmon_gene)]\n",
    "\n",
    "    patients += data.columns[2:].tolist()\n",
    "\n",
    "    # Match the CDR values in the 'info' dataframe with the 'class' values in 'fenzu'\n",
    "    fenzu = info.copy()\n",
    "    fenzu['BrainBank'] = fenzu['BrainBank'].astype(str).apply(lambda x: \"X\" + x)\n",
    "    fenzu = fenzu[fenzu['BrainBank'].isin(data.columns[2:])].reset_index(drop=True)\n",
    "    fenzu['CDR'] = fenzu['CDR'].apply(lambda x: 'CDR0' if x < 1 else ('CDR1' if x <= 2 else 'CDR2'))\n",
    "    fenzu = fenzu.loc[:, ['BrainBank', 'CDR']]\n",
    "    fenzu = fenzu.rename(columns={'BrainBank': 'list', 'CDR': 'class'})\n",
    "\n",
    "    # One-hot encode the 'class' values in 'fenzu'\n",
    "    design = pd.get_dummies(fenzu['class'])\n",
    "    design.index = fenzu['list'].tolist()\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Save the column names (gene names)\n",
    "    lieming1 = data['genename'].tolist()\n",
    "    # Remove the first two columns, leaving only the gene features\n",
    "    data = data.iloc[:, 2:]\n",
    "    # Set the row index of 'data' to be the gene names\n",
    "    data.index = lieming1\n",
    "\n",
    "    # CDR1-CDR0\n",
    "    # Prepare data for limma differential analysis\n",
    "    # Create a contrast matrix using the 'limma' package in R\n",
    "    limma = importr(\"limma\")\n",
    "    contrast_matrix = limma.makeContrasts(\"CDR1-CDR0\", levels=design)\n",
    "\n",
    "    # Start the analysis - step 1\n",
    "    fit = limma.lmFit(data, design)\n",
    "    # Step 2\n",
    "    fit2 = limma.contrasts_fit(fit, contrast_matrix)\n",
    "    fit2 = limma.eBayes(fit2)\n",
    "    # Step 3\n",
    "    tempOutput = limma.topTable(fit2, adjust=\"fdr\", n=float(\"inf\"))\n",
    "    # Remove rows with missing values\n",
    "    nrDEG = tempOutput.dropna()\n",
    "    diffsig = nrDEG.copy()\n",
    "\n",
    "    # Use criteria: |logFC| > 0.585 and padj < 0.05 (adjusted P-value)\n",
    "    foldChange = 0.585\n",
    "    padj = 0.05\n",
    "    # Filter for all differential genes based on the criteria\n",
    "    All_diffSig = diffsig.loc[(diffsig['P.Value'] < padj) & (\n",
    "        (diffsig['logFC'] > foldChange) | (diffsig['logFC'] < -foldChange))]\n",
    "\n",
    "    # Upregulated genes\n",
    "    diffup = All_diffSig.loc[(All_diffSig['P.Value'] < padj)\n",
    "                            & (All_diffSig['logFC'] > foldChange)]\n",
    "\n",
    "    # Downregulated genes\n",
    "    diffdown = All_diffSig.loc[(All_diffSig['P.Value'] < padj) & (\n",
    "        All_diffSig['logFC'] < -foldChange)]\n",
    "\n",
    "    CDR10.append(len(All_diffSig))\n",
    "    CDR1CDR0 = All_diffSig.index.tolist()\n",
    "\n",
    "    up_gene10.append(len(diffup))\n",
    "    down_gene10.append(len(diffdown))\n",
    "\n",
    "    # CDR2-CDR0\n",
    "    # Prepare data for limma differential analysis\n",
    "    # Create a contrast matrix using the 'limma' package in R\n",
    "    limma = importr(\"limma\")\n",
    "    contrast_matrix = limma.makeContrasts(\"CDR2-CDR0\", levels=design)\n",
    "\n",
    "    # Start the analysis - step 1\n",
    "    fit = limma.lmFit(data, design)\n",
    "    # Step 2\n",
    "    fit2 = limma.contrasts_fit(fit, contrast_matrix)\n",
    "    fit2 = limma.eBayes(fit2)\n",
    "    # Step 3\n",
    "    tempOutput = limma.topTable(fit2, adjust=\"fdr\", n=float(\"inf\"))\n",
    "    # Remove rows with missing values\n",
    "    nrDEG = tempOutput.dropna()\n",
    "    diffsig = nrDEG.copy()\n",
    "\n",
    "    # Use criteria: |logFC| > 0.585 and padj < 0.05 (adjusted P-value)\n",
    "    foldChange = 0.585\n",
    "    padj = 0.05\n",
    "    # Filter for all differential genes based on the criteria\n",
    "    All_diffSig = diffsig.loc[(diffsig['P.Value'] < padj) & (\n",
    "        (diffsig['logFC'] > foldChange) | (diffsig['logFC'] < -foldChange))]\n",
    "\n",
    "    # Upregulated genes\n",
    "    diffup = All_diffSig.loc[(All_diffSig['P.Value'] < padj)\n",
    "                            & (All_diffSig['logFC'] > foldChange)]\n",
    "\n",
    "    # Downregulated genes\n",
    "    diffdown = All_diffSig.loc[(All_diffSig['P.Value'] < padj) & (\n",
    "        All_diffSig['logFC'] < -foldChange)]\n",
    "\n",
    "    CDR20.append(len(All_diffSig))\n",
    "    CDR2CDR0 = All_diffSig.index.tolist()\n",
    "\n",
    "    up_gene20.append(len(diffup))\n",
    "    down_gene20.append(len(diffdown))\n",
    "\n",
    "    # CDR2-CDR1\n",
    "    # Prepare data for limma differential analysis\n",
    "    # Create a contrast matrix using the 'limma' package in R\n",
    "    limma = importr(\"limma\")\n",
    "    contrast_matrix = limma.makeContrasts(\"CDR2-CDR1\", levels=design)\n",
    "\n",
    "    # Start the analysis - step 1\n",
    "    fit = limma.lmFit(data, design)\n",
    "    # Step 2\n",
    "    fit2 = limma.contrasts_fit(fit, contrast_matrix)\n",
    "    fit2 = limma.eBayes(fit2)\n",
    "    # Step 3\n",
    "    tempOutput = limma.topTable(fit2, adjust=\"fdr\", n=float(\"inf\"))\n",
    "    # Remove rows with missing values\n",
    "    nrDEG = tempOutput.dropna()\n",
    "    diffsig = nrDEG.copy()\n",
    "\n",
    "    # Use criteria: |logFC| > 0.585 and padj < 0.05 (adjusted P-value)\n",
    "    foldChange = 0.585\n",
    "    padj = 0.05\n",
    "    # Filter for all differential genes based on the criteria\n",
    "    All_diffSig = diffsig.loc[(diffsig['P.Value'] < padj) & (\n",
    "        (diffsig['logFC'] > foldChange) | (diffsig['logFC'] < -foldChange))]\n",
    "\n",
    "    # Upregulated genes\n",
    "    diffup = All_diffSig.loc[(All_diffSig['P.Value'] < padj)\n",
    "                            & (All_diffSig['logFC'] > foldChange)]\n",
    "\n",
    "    # Downregulated genes\n",
    "    diffdown = All_diffSig.loc[(All_diffSig['P.Value'] < padj) & (\n",
    "        All_diffSig['logFC'] < -foldChange)]\n",
    "\n",
    "    CDR21.append(len(All_diffSig))\n",
    "    CDR2CDR1 = All_diffSig.index.tolist()\n",
    "\n",
    "    # Find the union of differential genes\n",
    "    dif_gene_ = set(CDR1CDR0).union(CDR2CDR0, CDR2CDR1)\n",
    "    gene_num.append(len(dif_gene_))\n",
    "    CDRAll = CDRAll | dif_gene_  #1014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_num\n",
    "len(CDRAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_gene['dif_gene_num'] = gene_num\n",
    "dif_gene['CDR1VSCDR0'] =CDR10\n",
    "dif_gene['CDR2VSCDR0'] =CDR20\n",
    "dif_gene['CDR2VSCDR1'] =CDR21\n",
    "\n",
    "dif_gene['up_gene10'] = up_gene10\n",
    "dif_gene['down_gene10'] = down_gene10\n",
    "dif_gene['up_gene20'] = up_gene20\n",
    "dif_gene['down_gene20'] = down_gene20\n",
    "dif_gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for dif_gene_num\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(dif_gene['Region'], dif_gene['dif_gene_num'], width=0.3, color='tan') # , color='tan'\n",
    "for i in range(len(dif_gene)):\n",
    "    plt.text(dif_gene['Region'][i], dif_gene['dif_gene_num'][i]+2, dif_gene['dif_gene_num'][i], ha='center', va='bottom')\n",
    "# plt.ylim((0, 25))\n",
    "plt.ylabel('Number of Differential Genes')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax = plt.gca()  # Get the axis\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# ax.axis.grid(color='lightgray',linewidth=0.5,alpha=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_gene = pd.DataFrame({'Mid-term Group': [dif_gene['up_gene10'].sum(), dif_gene['down_gene10'].sum()], \n",
    "              'Late-term Group': [dif_gene['up_gene20'].sum(),dif_gene['down_gene20'].sum()]}, index=['Upregulated Genes','Downregulated Genes'])\n",
    "up_down_gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2)\n",
    "width = 0.3\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, up_down_gene['Mid-term Group'], width, label='Mid-term Group', color='tan')\n",
    "rects2 = ax.bar(x + width/2, up_down_gene['Late-term Group'], width, label='Late-term Group', color='steelblue')\n",
    "ax.set_ylabel('Significant Genes Count (Count)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Upregulated Genes', 'Downregulated Genes'])\n",
    "ax.legend()\n",
    "\n",
    "# Adding numbers as text labels\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # Vertical text offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list to store the names of differentially expressed genes\n",
    "genenames = []\n",
    "\n",
    "# Iterating through the set CDRAll, which contains the union of differentially expressed genes\n",
    "for g_name in CDRAll:\n",
    "    genenames.append(g_name)\n",
    "\n",
    "# Sorting the gene names in alphabetical order\n",
    "genenames = sorted(genenames)\n",
    "\n",
    "# Determining the total number of unique genes in the list\n",
    "total_unique_genes = len(genenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(genenames,columns=['genename']).to_csv('genenames_1014.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19 Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDRframe = CDRframe[CDRframe['genename'].isin(conmon_gene)]\n",
    "CDRframe['genenum'] = 1\n",
    "\n",
    "for i in range(1,19):\n",
    "    data = pd.read_csv(micepath+micefiles[i])\n",
    "    data = data[data['genename'].isin(conmon_gene)]\n",
    "    data['genenum'] = i+1\n",
    "\n",
    "    CDRframe = pd.concat([CDRframe, data], join='outer', ignore_index=True)\n",
    "\n",
    "CDRframe.sort_values(by=['genename','genenum'], inplace=True)\n",
    "CDRframe.reset_index(drop=True,inplace=True)\n",
    "CDRframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDRframe.to_csv('CDRframe.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurrences of each patient's data in the 'patients' list\n",
    "patient_counts = pd.value_counts(patients)\n",
    "\n",
    "# Creating a DataFrame to store the patient and their corresponding data occurrence counts\n",
    "patients_times = pd.DataFrame(patient_counts)\n",
    "\n",
    "# Resetting the index of the DataFrame to have a 'patient' column\n",
    "patients_times.reset_index(inplace=True)\n",
    "\n",
    "# Renaming the columns of the DataFrame to 'patient' and 'times'\n",
    "patients_times.columns = ['patient', 'times']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering patients with data from at least 3 brain regions\n",
    "patient3 = patients_times[patients_times['times'] >= 3]['patient'].to_list()\n",
    "\n",
    "# Sorting the patient identifiers\n",
    "patient3 = sorted(patient3)\n",
    "\n",
    "# Getting the count of such patients\n",
    "num_patient3 = len(patient3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient3.insert(0,'genename')\n",
    "patient3.insert(1,'genenum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(patient3,columns=['patient']).to_csv('patient3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDR10_FC = pd.DataFrame()\n",
    "CDR20_FC = pd.DataFrame()\n",
    "CDR21_FC = pd.DataFrame()\n",
    "\n",
    "for m in range(len(micefiles)):\n",
    "    # Read data from a CSV file\n",
    "    data = pd.read_csv(micepath + micefiles[m])\n",
    "    # Filter data based on common genes\n",
    "    data = data[data['genename'].isin(common_gene)]\n",
    "\n",
    "    # Extract the list of patients\n",
    "    patient_list = data.columns[2:]\n",
    "\n",
    "    # Map CDR values from 'info' to 'fenzu' class\n",
    "    fenzu = info.copy()\n",
    "    fenzu['BrainBank'] = fenzu['BrainBank'].astype(str).apply(lambda x: \"X\" + x)\n",
    "    fenzu = fenzu[fenzu['BrainBank'].isin(patient_list)].reset_index(drop=True)\n",
    "    fenzu['CDR'] = fenzu['CDR'].apply(lambda x: 'CDR0' if x < 1 else ('CDR1' if x <= 2 else 'CDR2'))\n",
    "    fenzu = fenzu.loc[:, ['BrainBank', 'CDR']]\n",
    "    fenzu = fenzu.rename(columns={'BrainBank': 'list', 'CDR': 'class'})\n",
    "\n",
    "    # Encode the 'class' column as one-hot vectors\n",
    "    design = pd.get_dummies(fenzu['class'])\n",
    "    design.index = fenzu['list'].tolist()\n",
    "\n",
    "    # Drop rows with missing values in the data\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Store the gene names in 'lieming1'\n",
    "    lieming1 = data['genename'].tolist()\n",
    "    \n",
    "    # Remove the first two columns (gene identifier and description)\n",
    "    data = data.iloc[:, 2:]\n",
    "\n",
    "    # Set the row index of 'data' to 'genename'\n",
    "    data.index = lieming1\n",
    "\n",
    "    # CDR1-CDR0\n",
    "    limma = importr(\"limma\")\n",
    "    contrast_matrix = limma.makeContrasts(\"CDR1-CDR0\", levels=design)\n",
    "    fit = limma.lmFit(data, design)\n",
    "    fit2 = limma.contrasts_fit(fit, contrast_matrix)\n",
    "    fit2 = limma.eBayes(fit2)\n",
    "    tempOutput = limma.topTable(fit2, adjust=\"fdr\", n=float(\"inf\"))\n",
    "    nrDEG = tempOutput.dropna()\n",
    "    diffsig = nrDEG.copy()\n",
    "    diffsig.reset_index(inplace=True)\n",
    "    diffsig['Region'] = m + 1\n",
    "    CDR10_temp = diffsig[diffsig['index'].isin(genenames)]\n",
    "    CDR10_FC = pd.concat([CDR10_FC, CDR10_temp], join='outer', ignore_index=True)\n",
    "\n",
    "    # CDR2-CDR0\n",
    "    contrast_matrix = limma.makeContrasts(\"CDR2-CDR0\", levels=design)\n",
    "    fit = limma.lmFit(data, design)\n",
    "    fit2 = limma.contrasts_fit(fit, contrast_matrix)\n",
    "    fit2 = limma.eBayes(fit2)\n",
    "    tempOutput = limma.topTable(fit2, adjust=\"fdr\", n=float(\"inf\"))\n",
    "    nrDEG = tempOutput.dropna()\n",
    "    diffsig = nrDEG.copy()\n",
    "    diffsig.reset_index(inplace=True)\n",
    "    diffsig['Region'] = m + 1\n",
    "    CDR20_temp = diffsig[diffsig['index'].isin(genenames)]\n",
    "    CDR20_FC = pd.concat([CDR20_FC, CDR20_temp], join='outer', ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fenzu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDR10_FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDR20_FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDR10_FC.sort_values(by=['index','Region'], inplace=True)\n",
    "CDR20_FC.sort_values(by=['index','Region'], inplace=True)\n",
    "CDR20_FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDR10_FC['index'].to_list() == CDR20_FC['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC = pd.DataFrame({\"CDR1FC\": CDR10_FC['logFC'].to_list()\n",
    "                  ,\"CDR2FC\": CDR20_FC['logFC'].to_list() \n",
    "                })\n",
    "FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive10  = np.where(FC['CDR1FC'] > 0)[0].tolist()\n",
    "positive20  = np.where(FC['CDR2FC'] > 0)[0].tolist()\n",
    "CDR10_FC['index'].to_list() == CDR20_FC['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace negative values with their absolute values\n",
    "FC[FC < 0] = -FC\n",
    "# Add a 'genename' column from CDR10_FC's 'index' values\n",
    "FC['genename'] = CDR10_FC['index'].to_list()\n",
    "# Select specific columns 'genename', 'CDR1FC', and 'CDR2FC'\n",
    "FC = FC[['genename', 'CDR1FC', 'CDR2FC']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the weights of non-significant genes in 'CDR1FC' to 0\n",
    "FC.loc[FC['CDR1FC'] < 0.585, 'CDR1FC'] = 0\n",
    "# Add a small value to prevent all-zero genes\n",
    "FC['CDR1FC'] += 0.000001\n",
    "\n",
    "# Set the weights of non-significant genes in 'CDR2FC' to 0\n",
    "FC.loc[FC['CDR2FC'] < 0.585, 'CDR2FC'] = 0\n",
    "# Add a small value to prevent all-zero genes\n",
    "FC['CDR2FC'] += 0.000001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC['CDR1FC'].sum() , FC['CDR2FC'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter CDRframe to include only patients with data in at least 3 brain regions\n",
    "CDRframe = CDRframe.loc[:, patient3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDRframe = CDRframe[CDRframe['genename'].isin(genenames)]\n",
    "CDRframe.shape, CDRframe.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen in genenames:\n",
    "    # Filter the data for the current gene\n",
    "    genedata = CDRframe.loc[CDRframe['genename'] == gen, :]\n",
    "\n",
    "    # Calculate the centering for each column (subtract minimum value)\n",
    "    center = genedata.iloc[:, 2:].apply(lambda x: x - np.nanmin(x), axis=0)\n",
    "    \n",
    "    # Calculate the range (maximum - minimum) for each column\n",
    "    R = np.nanmax(genedata.iloc[:, 2:], axis=0) - np.nanmin(genedata.iloc[:, 2:], axis=0)\n",
    "    \n",
    "    # Normalize the centered data by dividing by the range (scaling)\n",
    "    x_star = center / R[np.newaxis, :]\n",
    "\n",
    "    # Further normalize the data by multiplying by 3 and adding 1\n",
    "    genedata.iloc[:, 2:] = x_star * 3 + 1\n",
    "\n",
    "    # Update the normalized data in the original DataFrame\n",
    "    CDRframe.loc[CDRframe['genename'] == gen, CDRframe.columns[2:]] = genedata.iloc[:, 2:]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "CDRframe.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDRframe.iloc[:,2:].sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = CDRframe.columns[2:]\n",
    "group = info.copy()\n",
    "group['BrainBank'] = group['BrainBank'].astype(str).apply(lambda x: \"X\" + x)\n",
    "group = group[group['BrainBank'].isin(list)].reset_index(drop=True)\n",
    "group['CDR'] = group['CDR'].apply(lambda x: 'CDR0' if x < 1 else ('CDR1' if x <= 2 else 'CDR2'))\n",
    "group = group.loc[:,['BrainBank','CDR']]\n",
    "group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BrainBank = group['BrainBank'].to_list()\n",
    "\n",
    "# Create a weighted data table\n",
    "FChou = pd.DataFrame(index=genenames, columns=BrainBank)\n",
    "FChou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen in FChou.index:\n",
    "    for m in FChou.columns:\n",
    "        brain_data = CDRframe.loc[CDRframe['genename'] == gen, m]\n",
    "        degree = group[group['BrainBank'] == m]['CDR'].tolist()[0]\n",
    "\n",
    "        if degree == \"CDR0\":\n",
    "            non_nan_series = brain_data.dropna()\n",
    "            FChou.loc[gen, m] = np.mean(non_nan_series)\n",
    "\n",
    "        elif degree == \"CDR1\":\n",
    "            weights = FC.loc[FC['genename'] == gen, \"CDR1FC\"]\n",
    "            weights = weights[(-brain_data.isna()).to_list()]\n",
    "            brain_data = brain_data.dropna()\n",
    "            FChou.loc[gen, m] = np.dot(weights / np.sum(weights), brain_data)\n",
    "\n",
    "        else:\n",
    "            weights = FC.loc[FC['genename'] == gen, \"CDR2FC\"]\n",
    "            weights = weights[(-brain_data.isna()).to_list()]\n",
    "            brain_data = brain_data.dropna()\n",
    "            FChou.loc[gen, m] = np.dot(weights / np.sum(weights), brain_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FChou.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FChou = FChou.astype(float)\n",
    "FChou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'CDR' column to one-hot encoding\n",
    "design = pd.get_dummies(group['CDR'])\n",
    "design.index = group['BrainBank'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDR1-CDR0  \n",
    "# Differential analysis using limma  Data preparation\n",
    "# Create a contrast matrix using the limma package in R\n",
    "limma = importr(\"limma\")\n",
    "contrast_matrix = limma.makeContrasts(\"CDR1-CDR0\", levels=design)\n",
    "\n",
    "# Start the analysis - Step 1\n",
    "fit = limma.lmFit(FChou, design)\n",
    "# Step 2\n",
    "fit2 = limma.contrasts_fit(fit, contrast_matrix)\n",
    "fit2 = limma.eBayes(fit2)\n",
    "# Step 3\n",
    "tempOutput = limma.topTable(fit2, adjust=\"fdr\", n=float(\"inf\"))\n",
    "# Remove rows with missing values\n",
    "nrDEG = tempOutput.dropna()\n",
    "diffsig = nrDEG.copy()\n",
    "\n",
    "# We use |logFC| > 0.585 and padj < 0.05 (adjusted P-value) as thresholds\n",
    "foldChange = 0.585\n",
    "padj = 0.05\n",
    "\n",
    "# Filter out all differentially expressed genes\n",
    "All_diffSig10 = diffsig.loc[(diffsig['P.Value'] < padj) & (\n",
    "    (diffsig['logFC'] > foldChange) | (diffsig['logFC'] < -foldChange))]\n",
    "\n",
    "# Upregulated\n",
    "diffup10 = All_diffSig10.loc[(All_diffSig10['P.Value'] < padj)\n",
    "                        & (All_diffSig10['logFC'] > foldChange)]\n",
    "\n",
    "# Downregulated\n",
    "diffdown10 = All_diffSig10.loc[(All_diffSig10['P.Value'] < padj) & (\n",
    "    All_diffSig10['logFC'] < -foldChange)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDR2-CDR0  \n",
    "# Differential analysis using limma  Data preparation\n",
    "# Create a contrast matrix using the limma package in R\n",
    "limma = importr(\"limma\")\n",
    "contrast_matrix = limma.makeContrasts(\"CDR2-CDR0\", levels=design)\n",
    "\n",
    "# Start the analysis - Step 1\n",
    "fit = limma.lmFit(FChou, design)\n",
    "# Step 2\n",
    "fit2 = limma.contrasts_fit(fit, contrast_matrix)\n",
    "fit2 = limma.eBayes(fit2)\n",
    "# Step 3\n",
    "tempOutput = limma.topTable(fit2, adjust=\"fdr\", n=float(\"inf\"))\n",
    "# Remove rows with missing values\n",
    "nrDEG = tempOutput.dropna()\n",
    "diffsig = nrDEG.copy()\n",
    "\n",
    "# We use |logFC| > 0.585 and padj < 0.05 (adjusted P-value) as thresholds\n",
    "foldChange = 0.585\n",
    "padj = 0.05\n",
    "\n",
    "# Filter out all differentially expressed genes\n",
    "All_diffSig20 = diffsig.loc[(diffsig['P.Value'] < padj) & (\n",
    "    (diffsig['logFC'] > foldChange) | (diffsig['logFC'] < -foldChange))]\n",
    "\n",
    "# Upregulated\n",
    "diffup20 = All_diffSig20.loc[(All_diffSig20['P.Value'] < padj)\n",
    "                        & (All_diffSig20['logFC'] > foldChange)]\n",
    "\n",
    "# Downregulated\n",
    "diffdown20 = All_diffSig20.loc[(All_diffSig20['P.Value'] < padj) & (\n",
    "    All_diffSig20['logFC'] < -foldChange)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDR2-CDR1 \n",
    "# Differential analysis using limma  Data preparation\n",
    "# Create a contrast matrix using the limma package in R\n",
    "limma = importr(\"limma\")\n",
    "contrast_matrix = limma.makeContrasts(\"CDR2-CDR1\", levels=design)\n",
    "\n",
    "# Start the analysis - Step 1\n",
    "fit = limma.lmFit(FChou, design)\n",
    "# Step 2\n",
    "fit2 = limma.contrasts_fit(fit, contrast_matrix)\n",
    "fit2 = limma.eBayes(fit2)\n",
    "# Step 3\n",
    "tempOutput = limma.topTable(fit2, adjust=\"fdr\", n=float(\"inf\"))\n",
    "# Remove rows with missing values\n",
    "nrDEG = tempOutput.dropna()\n",
    "diffsig = nrDEG.copy()\n",
    "\n",
    "# We use |logFC| > 0.585 and padj < 0.05 (adjusted P-value) as thresholds\n",
    "foldChange = 0.585\n",
    "padj = 0.05\n",
    "\n",
    "# Filter out all differentially expressed genes\n",
    "All_diffSig21 = diffsig.loc[(diffsig['P.Value'] < padj) & (\n",
    "    (diffsig['logFC'] > foldChange) | (diffsig['logFC'] < -foldChange))]\n",
    "\n",
    "# Upregulated\n",
    "diffup21 = All_diffSig21.loc[(All_diffSig21['P.Value'] < padj)\n",
    "                        & (All_diffSig21['logFC'] > foldChange)]\n",
    "\n",
    "# Downregulated\n",
    "diffdown21 = All_diffSig21.loc[(All_diffSig21['P.Value'] < padj) & (\n",
    "    All_diffSig21['logFC'] < -foldChange)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limma_all = [len(All_diffSig10), len(All_diffSig20), len(All_diffSig21)]\n",
    "limma_up = [len(diffup10), len(diffup20), len(diffup21)]\n",
    "limma_down = [len(diffdown10), len(diffdown20), len(diffdown21)]\n",
    "\n",
    "limma_diff = pd.DataFrame(index=['CDR1-CDR0', 'CDR2-CDR0', 'CDR2-CDR1'])\n",
    "limma_diff['All Differential Genes'] = limma_all\n",
    "limma_diff['Upregulated Genes'] = limma_up\n",
    "limma_diff['Downregulated Genes'] = limma_down\n",
    "limma_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limma_all_gene = set(All_diffSig10.index.to_list()).union(All_diffSig20.index.to_list(), All_diffSig21.index.to_list())\n",
    "len(limma_all_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limma_data = FChou.loc[limma_all_gene,:]\n",
    "limma_data.sort_index(inplace=True)\n",
    "limma_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limma_data.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenerl_curve = limma_data.copy()\n",
    "kenerl_curve.columns = group['CDR']\n",
    "kenerl_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDR0 = []\n",
    "CDR1 = []\n",
    "CDR2 = []\n",
    "for i in range(len(group)):\n",
    "    if group['CDR'][i] == 'CDR0':\n",
    "        CDR0 = CDR0 + kenerl_curve.iloc[:,i].to_list()\n",
    "    elif group['CDR'][i] == 'CDR1':\n",
    "        CDR1 = CDR1 + kenerl_curve.iloc[:,i].to_list()\n",
    "    else:\n",
    "        CDR2 = CDR2 + kenerl_curve.iloc[:,i].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(CDR0, shade=True)\n",
    "sns.kdeplot(CDR1, shade=True)\n",
    "sns.kdeplot(CDR2, shade=True)\n",
    "plt.legend(['Early', 'Intermediate', 'Late'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rpy2.robjects import pandas2ri\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Standardisation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn. preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_limma = pd.DataFrame(scaler.fit_transform(limma_data), columns= limma_data.columns , index = limma_data.index)\n",
    "\n",
    "scaled_limma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Downgraded to 5 dimensions using UMAP (downgraded for number of samples, not for number of genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "reducer = umap.UMAP(n_components=5, n_epochs=500,random_state=42,\n",
    "                    metric='euclidean', n_neighbors=30, min_dist=0.1)\n",
    "reduced_data = reducer.fit_transform(scaled_limma)\n",
    "reduced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Exploring the optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "model = KMeans()\n",
    "\n",
    "visualizer = KElbowVisualizer(model, k=(2,10), timings=True)\n",
    "visualizer.fit(reduced_data)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Clustering of dimensionality reduced data using kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=42)  # Specify the number of clusters\n",
    "clusters = kmeans.fit(reduced_data)\n",
    "# clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming reduced_data is UMAP-embedded data and clusters.labels_ contains cluster assignments\n",
    "\n",
    "# Create a figure for the scatter plot\n",
    "plt.figure(figsize=(10.5, 7))\n",
    "\n",
    "# Get unique cluster labels\n",
    "unique_labels = np.unique(clusters.labels_)\n",
    "\n",
    "# Define a mapping of cluster labels\n",
    "category_colors = {\n",
    "    \"Cluster A\": \"blue\",\n",
    "    \"Cluster B\": \"green\",\n",
    "    \"Cluster C\": \"orange\",\n",
    "    \"Cluster D\": \"red\",\n",
    "    \"Cluster E\": \"purple\"\n",
    "}\n",
    "# Initialize a list to store legend handles\n",
    "legend_handles = []\n",
    "categories = ['Cluster A', 'Cluster B', 'Cluster C', 'Cluster D', 'Cluster E']\n",
    "\n",
    "# Loop through different clusters and assign a unique color and label to each\n",
    "for label in unique_labels:\n",
    "    cluster_points = reduced_data[clusters.labels_ == label]\n",
    "\n",
    "    # Get the corresponding category label\n",
    "    category_label = categories[label]\n",
    "\n",
    "    # Get the color for the category label from the mapping\n",
    "    color = category_colors.get(category_label, 'gray')  # Default to gray if not found\n",
    "\n",
    "    # Plot the cluster points with the assigned color and label\n",
    "    scatter = plt.scatter(cluster_points[:, 0], cluster_points[:, 1], s=10, alpha=0.7, label=f'{category_label}', color=color)\n",
    "\n",
    "    # Append the scatter object to the legend handles\n",
    "    legend_handles.append(scatter)\n",
    "\n",
    "# Set font weight for x and y axis labels\n",
    "plt.rc('axes', labelweight='bold')\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('KMeans Clustering Results', fontsize=22)\n",
    "plt.xlabel('UMAP Dimension 1', fontsize=22)\n",
    "plt.ylabel('UMAP Dimension 2', fontsize=22)\n",
    "\n",
    "plt.xticks(fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "# Add legend with increased marker size\n",
    "legend = plt.legend(handles=legend_handles, loc='upper left', fontsize=25)\n",
    "for legend_handle in legend.legendHandles:\n",
    "    legend_handle.set_sizes([150])  # Adjust the size as needed\n",
    "\n",
    "# Save the plot as a PDF file\n",
    "plt.savefig(\"old_3_KMeans.pdf\", format=\"pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Splicing the results after gene clustering with the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_data = scaled_limma.copy()\n",
    "cluster_data['label'] = clusters.labels_\n",
    "cluster_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The number of Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "element_counts = Counter(cluster_data['label'])\n",
    "\n",
    "# print results\n",
    "for element, count in element_counts.items():\n",
    "    print(f\"{element}: {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plotting the number of genes on a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of categories and corresponding colors\n",
    "category_colors = {\n",
    "    \"Cluster A\": \"blue\",\n",
    "    \"Cluster B\": \"green\",\n",
    "    \"Cluster C\": \"orange\",\n",
    "    \"Cluster D\": \"red\",\n",
    "    \"Cluster E\": \"purple\"\n",
    "}\n",
    "\n",
    "# Assuming you have a list of categories and corresponding values\n",
    "categories = [\"Cluster A\", \"Cluster B\", \"Cluster C\", \"Cluster D\", \"Cluster E\"]\n",
    "values = [61, 28, 50, 27, 31]\n",
    "\n",
    "# Create Seaborn style bar plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Specify the bar width\n",
    "bar_width = 0.4\n",
    "\n",
    "# Create the bar plot and set the palette based on category_colors\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=categories, y=values, palette=[category_colors[cat] for cat in categories], ci=None, capsize=0.2, width=bar_width)\n",
    "\n",
    "# Set the font weight for the x and y axis labels\n",
    "plt.rc('axes', labelweight='bold')\n",
    "\n",
    "# Set the labels for x and y axes\n",
    "plt.xlabel(\"Clusters\", fontsize=13)\n",
    "plt.ylabel(\"Number of Genes\",  fontsize=13)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF file\n",
    "plt.savefig(\"old_3_numbers.pdf\", format=\"pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Extraction of the first principal component for each type of gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "cluster_class_data  = pd.DataFrame()\n",
    "for m in range(5):\n",
    "    class_m = cluster_data[cluster_data['label'] == m]\n",
    "    class_m = class_m.iloc[:,:-1].T\n",
    "    # first principal component\n",
    "    pca = PCA(n_components=1)\n",
    "    cluster_class_data = pd.concat([cluster_class_data, pd.DataFrame(pca.fit_transform(class_m)[:,0])], axis=1)\n",
    "\n",
    "\n",
    "cluster_class_data.columns = [\"ClusterA\", \"ClusterB\", \"ClusterC\", \"ClusterD\", \"ClusterE\"]\n",
    "\n",
    "cluster_class_data['fenzu_list'] = cluster_data.columns[:-1]\n",
    "cluster_class_data= pd.merge(cluster_class_data, group, left_on='fenzu_list',right_on='BrainBank')\n",
    "\n",
    "cluster_class_data.drop(['fenzu_list','BrainBank'],axis=1,inplace=True)\n",
    "cluster_class_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Calculate the variance contribution of the first principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in range(5):\n",
    "    class_m = cluster_data[cluster_data['label'] == m]\n",
    "    class_m = class_m.iloc[:,:-1].T\n",
    "    # first principal component\n",
    "    pca = PCA()\n",
    "    pca.fit_transform(class_m)\n",
    "    first_principal_component_variance = pca.explained_variance_[0]  # Variance of the first principal component\n",
    "    total_variance = np.sum(pca.explained_variance_)  # total variance\n",
    "    contribution_ratio = first_principal_component_variance / total_variance\n",
    "    print(contribution_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plotting the bar chart of the variance contribution of the first principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of categories and corresponding colors\n",
    "category_colors = {\n",
    "    \"Cluster A\": \"blue\",\n",
    "    \"Cluster B\": \"green\",\n",
    "    \"Cluster C\": \"orange\",\n",
    "    \"Cluster D\": \"red\",\n",
    "    \"Cluster E\": \"purple\"\n",
    "}\n",
    "\n",
    "categories = [\"Cluster A\", \"Cluster B\", \"Cluster C\", \"Cluster D\", \"Cluster E\"]\n",
    "values = [0.1699216032427904, 0.5338668529769856, 0.3711736837129753, 0.521321272697422, 0.5364056091241008]\n",
    "\n",
    "# Create Seaborn style bar plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Specify the bar width\n",
    "bar_width = 0.4\n",
    "\n",
    "# Create the bar plot and set the palette based on category_colors\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=categories, y=values, palette=[category_colors[cat] for cat in categories], ci=None, capsize=0.2, width=bar_width)\n",
    "\n",
    "# Set the font weight for the x and y axis labels\n",
    "plt.rc('axes', labelweight='bold')\n",
    "\n",
    "# Set the labels for x and y axes\n",
    "plt.xlabel(\"Clusters\", fontsize=13)\n",
    "plt.ylabel(\"Variance contribution rates\", fontsize=13)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF file\n",
    "plt.savefig(\"old_3_contribution.pdf\", format=\"pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Decision Tree Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "cluster_class_data = shuffle(cluster_class_data, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Disrupt the order of the samples 20 times and calculate the average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_m_l = []\n",
    "e_m = []\n",
    "e_l = []\n",
    "m_l = []\n",
    "\n",
    "for i in range(20):\n",
    "    cluster_class_data = shuffle(cluster_class_data, random_state=i)\n",
    "\n",
    "    # early, middle and late stage\n",
    "    data1 = cluster_class_data.copy()\n",
    "    CART_tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=2, random_state=42)\n",
    "    temp1 = cross_val_score(CART_tree, data1.drop('CDR', axis=1),\n",
    "                            data1['CDR'], cv=5,n_jobs=-1).mean()\n",
    "    e_m_l.append(temp1)\n",
    "\n",
    "    # early and middle stage\n",
    "    data2 = cluster_class_data[cluster_class_data['CDR'] != 'CDR2']\n",
    "    CART_tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1, random_state=42)\n",
    "    temp2 = cross_val_score(CART_tree, data2.drop('CDR', axis=1),\n",
    "                            data2['CDR'], cv=5,n_jobs=-1).mean()\n",
    "    e_m.append(temp2)\n",
    "\n",
    "    # early and late stage\n",
    "    data3 = cluster_class_data[cluster_class_data['CDR'] != 'CDR1']\n",
    "    CART_tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1, random_state=42)\n",
    "    temp3 = cross_val_score(CART_tree, data3.drop('CDR', axis=1),\n",
    "                            data3['CDR'], cv=5,n_jobs=-1).mean()\n",
    "    e_l.append(temp3)\n",
    "\n",
    "    # middle and late stage\n",
    "    data4 = cluster_class_data[cluster_class_data['CDR'] != 'CDR0']\n",
    "    CART_tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1, random_state=42)\n",
    "    temp4 = cross_val_score(CART_tree, data4.drop('CDR', axis=1),\n",
    "                            data4['CDR'], cv=5,n_jobs=-1).mean()\n",
    "    m_l.append(temp4)\n",
    "\n",
    "print('early, middle and late stage：', np.mean(e_m_l))\n",
    "print('early and middle stage：', np.mean(e_m))\n",
    "print('early and late stage：', np.mean(e_l))\n",
    "print('middle and late stage：', np.mean(m_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " Disrupt the sample order 20 times and calculate the average feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View the classification features used for each cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "feature_importances_1 = []\n",
    "feature_importances_2 = []\n",
    "feature_importances_3 = []\n",
    "feature_importances_4 = []\n",
    "\n",
    "for i in range(20):\n",
    "    cluster_class_data = shuffle(cluster_class_data, random_state=i)\n",
    "\n",
    "    # early, middle and late stage---------------------------------------------------------------------------------\n",
    "    data1 = cluster_class_data.copy()\n",
    "\n",
    "    X = data1.drop('CDR', axis=1)\n",
    "    y = data1['CDR']\n",
    "    clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=2)\n",
    "    cv = KFold(n_splits=5,)\n",
    "\n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        importance = clf.feature_importances_\n",
    "        feature_importances_1.append(list(importance))\n",
    "\n",
    "\n",
    "    # early and middle stage---------------------------------------------------------------------------------\n",
    "    data2 = cluster_class_data[cluster_class_data['CDR'] != 'CDR2']\n",
    "\n",
    "    X = data2.drop('CDR', axis=1)\n",
    "    y = data2['CDR']\n",
    "    clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1)\n",
    "    cv = KFold(n_splits=5,)\n",
    "\n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        importance = clf.feature_importances_\n",
    "        feature_importances_2.append(list(importance))\n",
    "\n",
    "\n",
    "    # early and late stage---------------------------------------------------------------------------------\n",
    "    data3 = cluster_class_data[cluster_class_data['CDR'] != 'CDR1']\n",
    "\n",
    "    X = data3.drop('CDR', axis=1)\n",
    "    y = data3['CDR']\n",
    "    clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1)\n",
    "    cv = KFold(n_splits=5,)\n",
    "\n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        importance = clf.feature_importances_\n",
    "        feature_importances_3.append(list(importance))\n",
    "\n",
    "\n",
    "    # middle and late stage---------------------------------------------------------------------------------\n",
    "    data4 = cluster_class_data[cluster_class_data['CDR'] != 'CDR0']\n",
    "\n",
    "    X = data4.drop('CDR', axis=1)\n",
    "    y = data4['CDR']\n",
    "    clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1)\n",
    "    cv = KFold(n_splits=5,)\n",
    "\n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        importance = clf.feature_importances_\n",
    "        feature_importances_4.append(list(importance))\n",
    "\n",
    "\n",
    "\n",
    "# early, middle and late stage---------------------------------------------------------------------------------\n",
    "sums = [0] * len(feature_importances_1[0])\n",
    "for sublist in feature_importances_1:\n",
    "    for i, value in enumerate(sublist):\n",
    "        sums[i] += value\n",
    "num_sublists = len(feature_importances_1)\n",
    "averages = [total / num_sublists for total in sums]\n",
    "print(\"early, middle and late stage：\", averages)\n",
    "\n",
    "\n",
    "# early and middle stage---------------------------------------------------------------------------------\n",
    "sums = [0] * len(feature_importances_2[0])\n",
    "for sublist in feature_importances_2:\n",
    "    for i, value in enumerate(sublist):\n",
    "        sums[i] += value\n",
    "num_sublists = len(feature_importances_2)\n",
    "averages = [total / num_sublists for total in sums]\n",
    "print(\"early and middle stage：\", averages)\n",
    "\n",
    "\n",
    "# early and late stage---------------------------------------------------------------------------------\n",
    "sums = [0] * len(feature_importances_3[0])\n",
    "for sublist in feature_importances_3:\n",
    "    for i, value in enumerate(sublist):\n",
    "        sums[i] += value\n",
    "num_sublists = len(feature_importances_3)\n",
    "averages = [total / num_sublists for total in sums]\n",
    "print(\"early and late stage：\", averages)\n",
    "\n",
    "\n",
    "# middle and late stage---------------------------------------------------------------------------------\n",
    "sums = [0] * len(feature_importances_4[0])\n",
    "for sublist in feature_importances_4:\n",
    "    for i, value in enumerate(sublist):\n",
    "        sums[i] += value\n",
    "num_sublists = len(feature_importances_4)\n",
    "averages = [total / num_sublists for total in sums]\n",
    "print(\"middle and late stage：\", averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "number of the root node"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "feature_importances_1 = []\n",
    "feature_importances_2 = []\n",
    "feature_importances_3 = []\n",
    "feature_importances_4 = []\n",
    "\n",
    "for i in range(20):\n",
    "    cluster_class_data = shuffle(cluster_class_data, random_state=i)\n",
    "\n",
    "    # early, middle and late stage---------------------------------------------------------------------------------\n",
    "    data1 = cluster_class_data.copy()\n",
    "\n",
    "    X = data1.drop('CDR', axis=1)\n",
    "    y = data1['CDR']\n",
    "    clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=2, random_state=42)\n",
    "    cv = KFold(n_splits=5,)\n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        importance = clf.feature_importances_\n",
    "        feature_importances_1.append(list(importance))\n",
    "\n",
    "    # early and middle stage---------------------------------------------------------------------------------\n",
    "    data2 = cluster_class_data[cluster_class_data['CDR'] != 'CDR2']\n",
    "\n",
    "    X = data2.drop('CDR', axis=1)\n",
    "    y = data2['CDR']\n",
    "    clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1, random_state=42)\n",
    "    cv = KFold(n_splits=5,)\n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        importance = clf.feature_importances_\n",
    "        feature_importances_2.append(list(importance))\n",
    "\n",
    "    # early and late stage---------------------------------------------------------------------------------\n",
    "    data3 = cluster_class_data[cluster_class_data['CDR'] != 'CDR1']\n",
    "\n",
    "    X = data3.drop('CDR', axis=1)\n",
    "    y = data3['CDR']\n",
    "    clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1, random_state=42)\n",
    "    cv = KFold(n_splits=5,)\n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        importance = clf.feature_importances_\n",
    "        feature_importances_3.append(list(importance))\n",
    "\n",
    "    # middle and late stage---------------------------------------------------------------------------------\n",
    "    data4 = cluster_class_data[cluster_class_data['CDR'] != 'CDR0']\n",
    "\n",
    "    X = data4.drop('CDR', axis=1)\n",
    "    y = data4['CDR']\n",
    "    clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1, random_state=42)\n",
    "    cv = KFold(n_splits=5,)\n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        importance = clf.feature_importances_\n",
    "        feature_importances_4.append(list(importance))\n",
    "\n",
    "# early, middle and late stage---------------------------------------------------------------------------------\n",
    "num_1_1 = []\n",
    "num_1_2 = []\n",
    "\n",
    "for sublist in feature_importances_1:\n",
    "    max_index = sublist.index(max(sublist))\n",
    "    num_1_1.append(max_index)\n",
    "\n",
    "for sublist in feature_importances_1:\n",
    "    sorted_sublist = sorted(sublist, reverse=True)\n",
    "    second_max_value = sorted_sublist[1]\n",
    "    second_max_index = sublist.index(second_max_value)\n",
    "    num_1_2.append(second_max_index)\n",
    "\n",
    "count_1_1 = Counter(num_1_1)\n",
    "count_1_2 = Counter(num_1_2)\n",
    "\n",
    "for value, count in count_1_1.items():\n",
    "    print(f\"{value} cluster's genes serve as root nodes in the early, middle, and late stages {count} times\")\n",
    "\n",
    "print('----------------------------------------------')\n",
    "\n",
    "for value, count in count_1_2.items():\n",
    "    print(f\"{value} cluster's genes serve as secondary root nodes in the early, middle, and late stages {count} times\")\n",
    "\n",
    "print('----------------------------------------------')\n",
    "\n",
    "# early and middle stage---------------------------------------------------------------------------------\n",
    "num_2 = []\n",
    "\n",
    "for sublist in feature_importances_2:\n",
    "    max_index = sublist.index(max(sublist))\n",
    "    num_2.append(max_index)\n",
    "\n",
    "count_2 = Counter(num_2)\n",
    "\n",
    "for value, count in count_2.items():\n",
    "    print(f\"{value} cluster's genes serve as root nodes in the early and middle stages {count} times\")\n",
    "\n",
    "print('----------------------------------------------')\n",
    "\n",
    "# early and late stage---------------------------------------------------------------------------------\n",
    "num_3 = []\n",
    "\n",
    "for sublist in feature_importances_3:\n",
    "    max_index = sublist.index(max(sublist))\n",
    "    num_3.append(max_index)\n",
    "\n",
    "count_3 = Counter(num_3)\n",
    "\n",
    "for value, count in count_3.items():\n",
    "    print(f\"{value} cluster's genes serve as root nodes in the early and late stages {count} times\")\n",
    "\n",
    "print('----------------------------------------------')\n",
    "\n",
    "# middle and late stage---------------------------------------------------------------------------------\n",
    "num_4 = []\n",
    "\n",
    "for sublist in feature_importances_4:\n",
    "    max_index = sublist.index(max(sublist))\n",
    "    num_4.append(max_index)\n",
    "\n",
    "count_4 = Counter(num_4)\n",
    "\n",
    "for value, count in count_4.items():\n",
    "    print(f\"{value} cluster's genes serve as root nodes in the middle and late stages {count} times\")\n",
    "\n",
    "print('----------------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Early, middle and late decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_data_ = cluster_class_data.copy()\n",
    "\n",
    "feature=dt_data_.columns.to_list()[:-1]\n",
    "class_names = dt_data_['CDR'].unique()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CART_tree = DecisionTreeClassifier(\n",
    "    criterion='gini', splitter='best', max_depth=2)\n",
    "\n",
    "e_m_l = cross_val_score(CART_tree, dt_data_.drop('CDR', axis=1),\n",
    "                        dt_data_['CDR'], cv=5,n_jobs=-1).mean()\n",
    "\n",
    "e_m_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CART_tree = DecisionTreeClassifier(criterion='gini',splitter = 'best',max_depth=2)\n",
    "CART_tree.fit(dt_data_.drop('CDR', axis=1), dt_data_['CDR'])\n",
    "dot_data = tree.export_graphviz(CART_tree,\n",
    "                                feature_names=feature,\n",
    "                                class_names=[str(k) for k in np.unique(dt_data_['CDR'])],\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "X = cluster_class_data.iloc[:, :4]\n",
    "y = cluster_class_data.iloc[:, -1]\n",
    "\n",
    "y = y.replace({'CDR0': 0, 'CDR1': 1, 'CDR2': 2})\n",
    "\n",
    "y_binarized = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y_binarized.shape[1]\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binarized, test_size=.5, random_state=random_state)\n",
    "\n",
    "tree_classifier = DecisionTreeClassifier(random_state=random_state, max_depth=2)\n",
    "\n",
    "# build OneVsRestClassifier\n",
    "classifier = OneVsRestClassifier(tree_classifier)\n",
    "y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "# calculate ROC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "lw=2\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of CDR{0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 24)\n",
    "plt.ylabel('True Positive Rate', fontsize = 24)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "# plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\", fontsize = 14.5, frameon=False)\n",
    "\n",
    "plt.savefig(\"old_3_emlROC.pdf\", format=\"pdf\", bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Early and mid-term decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_data_ = cluster_class_data[cluster_class_data['CDR'] != 'CDR2']\n",
    "\n",
    "feature=dt_data_.columns.to_list()[:-1]\n",
    "class_names = dt_data_['CDR'].unique()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CART_tree = DecisionTreeClassifier(\n",
    "    criterion='gini', splitter='best', max_depth=1)\n",
    "\n",
    "e_m = cross_val_score(CART_tree, dt_data_.drop('CDR', axis=1),\n",
    "                      dt_data_['CDR'], cv=5,n_jobs=-1).mean()\n",
    "e_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CART_tree = DecisionTreeClassifier(criterion='gini',splitter = 'best',max_depth=1)\n",
    "CART_tree.fit(dt_data_.drop('CDR', axis=1), dt_data_['CDR'])\n",
    "dot_data = tree.export_graphviz(CART_tree,\n",
    "                                feature_names=feature,\n",
    "                                class_names=[str(k) for k in np.unique(dt_data_['CDR'])],\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_data_ = cluster_class_data[cluster_class_data['CDR'] != 'CDR2']\n",
    "\n",
    "X = dt_data_.iloc[:, :4]\n",
    "y = dt_data_.iloc[:, -1]\n",
    "\n",
    "y = y.replace({'CDR0': 0, 'CDR1': 1})\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score, drop_intermediate=True)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(6.6, 4.4))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 18)\n",
    "plt.ylabel('True Positive Rate', fontsize = 18)\n",
    "plt.legend(loc=\"lower right\", frameon=False, fontsize = 16)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.savefig(\"old_3_emROC.pdf\", format=\"pdf\", bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Early and Late Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_data_ = cluster_class_data[cluster_class_data['CDR'] != 'CDR1']\n",
    "\n",
    "feature=dt_data_.columns.to_list()[:-1]\n",
    "class_names = dt_data_['CDR'].unique()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CART_tree = DecisionTreeClassifier(\n",
    "    criterion='gini', splitter='best', max_depth=1)\n",
    "\n",
    "e_l = cross_val_score(CART_tree, dt_data_.drop('CDR', axis=1),\n",
    "                      dt_data_['CDR'], cv=5,n_jobs=-1).mean()\n",
    "e_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CART_tree = DecisionTreeClassifier(criterion='gini',splitter = 'best',max_depth=1)\n",
    "CART_tree.fit(dt_data_.drop('CDR', axis=1), dt_data_['CDR'])\n",
    "dot_data = tree.export_graphviz(CART_tree,\n",
    "                                feature_names=feature,\n",
    "                                class_names=[str(k) for k in np.unique(dt_data_['CDR'])],\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_data_ = cluster_class_data[cluster_class_data['CDR'] != 'CDR1']\n",
    "\n",
    "X = dt_data_.iloc[:, :4]\n",
    "y = dt_data_.iloc[:, -1]\n",
    "\n",
    "y = y.replace({'CDR0': 0, 'CDR2': 1})\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(6.6, 4.4))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 18)\n",
    "plt.ylabel('True Positive Rate', fontsize = 18)\n",
    "plt.legend(loc=\"lower right\", frameon=False, fontsize = 16)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.savefig(\"old_3_elROC.pdf\", format=\"pdf\", bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Middle and Late Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_data_ = cluster_class_data[cluster_class_data['CDR'] != 'CDR0']\n",
    "\n",
    "feature=dt_data_.columns.to_list()[:-1]\n",
    "class_names = dt_data_['CDR'].unique()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CART_tree = DecisionTreeClassifier(\n",
    "    criterion='gini', splitter='best', max_depth=1)\n",
    "\n",
    "m_l = cross_val_score(CART_tree, dt_data_.drop('CDR', axis=1),\n",
    "                      dt_data_['CDR'], cv=5,n_jobs=-1).mean()\n",
    "m_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CART_tree = DecisionTreeClassifier(criterion='gini',splitter = 'best',max_depth=1)\n",
    "CART_tree.fit(dt_data_.drop('CDR', axis=1), dt_data_['CDR'])\n",
    "dot_data = tree.export_graphviz(CART_tree,\n",
    "                                feature_names=feature,\n",
    "                                class_names=[str(k) for k in np.unique(dt_data_['CDR'])],\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_data_ = cluster_class_data[cluster_class_data['CDR'] != 'CDR0']\n",
    "\n",
    "X = dt_data_.iloc[:, :4]\n",
    "y = dt_data_.iloc[:, -1]\n",
    "\n",
    "y = y.replace({'CDR1': 0, 'CDR2': 1})\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(6.6, 4.4))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 18)\n",
    "plt.ylabel('True Positive Rate', fontsize = 18)\n",
    "plt.legend(loc=\"lower right\", frameon=False, fontsize = 16)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.savefig(\"old_3_mlROC.pdf\", format=\"pdf\", bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('e_m_l：', e_m_l)\n",
    "print('e_m：', e_m)\n",
    "print('e_l：', e_l)\n",
    "print('m_l：', m_l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
